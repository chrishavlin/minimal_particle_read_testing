{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "140f2188-7d61-4110-9365-39fc297d37d8",
   "metadata": {},
   "source": [
    "### exploration of distributed load methods\n",
    "\n",
    "During initial work at creating a daskified particle reader for yt, I've consistently seen that the daskified readers are a bit slower than yt's original particle reader. This isn't suprising because using a tool like dask introduces an overhead for communicating data. The full daskified reader, however, includes not just communication of data  but also serialization of complex yt dataset and index objects. \n",
    "\n",
    "So this notebook explores some simpler loading methods that isolate yt's chunking behavior from the serialization of yt objects. \n",
    "\n",
    "The associated functions used below are in `src/manual_loads.py`\n",
    "\n",
    "First, spin up a dask client to work with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9307cbbe-512e-4787-9fab-5c2b2d6e409b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "c = Client(n_workers=4, threads_per_worker= 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe195cb-a97a-4b32-ab01-be9501d4b03e",
   "metadata": {},
   "source": [
    "In order to avoid serializing yt objects, we'll use a function that pulls out all of the chunks corresponding to selecting all the data of a yt dataset:\n",
    "\n",
    "```\n",
    "ds = yt.load()\n",
    "ad = ds.all_data()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efc8df72-99bd-45df-8864-a7d39c6df0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.manual_loads import get_yt_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b590265d-969e-403b-8856-6488c6ff1380",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"snapshot_033/snap_033.0.hdf5\"\n",
    "field_type = \"PartType0\"\n",
    "field = \"Density\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4530f4d-ecaf-4ac3-9888-62f4f83f72ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "yt : [INFO     ] 2022-06-06 17:34:32,303 Parameters: current_time              = 4.343952725460923e+17 s\n",
      "yt : [INFO     ] 2022-06-06 17:34:32,305 Parameters: domain_dimensions         = [1 1 1]\n",
      "yt : [INFO     ] 2022-06-06 17:34:32,305 Parameters: domain_left_edge          = [0. 0. 0.]\n",
      "yt : [INFO     ] 2022-06-06 17:34:32,306 Parameters: domain_right_edge         = [25. 25. 25.]\n",
      "yt : [INFO     ] 2022-06-06 17:34:32,306 Parameters: cosmological_simulation   = 1\n",
      "yt : [INFO     ] 2022-06-06 17:34:32,307 Parameters: current_redshift          = -4.811891664902035e-05\n",
      "yt : [INFO     ] 2022-06-06 17:34:32,307 Parameters: omega_lambda              = 0.762\n",
      "yt : [INFO     ] 2022-06-06 17:34:32,307 Parameters: omega_matter              = 0.238\n",
      "yt : [INFO     ] 2022-06-06 17:34:32,307 Parameters: omega_radiation           = 0.0\n",
      "yt : [INFO     ] 2022-06-06 17:34:32,308 Parameters: hubble_constant           = 0.73\n",
      "yt : [INFO     ] 2022-06-06 17:34:32,379 Allocating for 4.194e+06 particles\n",
      "Loading particle index: 100%|███████████████████████████████████| 12/12 [00:00<00:00, 482.43it/s]\n"
     ]
    }
   ],
   "source": [
    "datafiles = get_yt_chunks(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad4b64f-7df9-4a8d-85e4-d8cd8092292f",
   "metadata": {},
   "source": [
    "and now we have a very simple list of the hdf files and start/end ranges that make up the yt index object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "356e8935-e588-42b8-af81-50bc830ae1ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'file': '/home/chavlin/hdd/data/yt_data/yt_sample_sets/snapshot_033/snap_033.0.hdf5',\n",
       "  'start_index': 0,\n",
       "  'end_index': 262144},\n",
       " {'file': '/home/chavlin/hdd/data/yt_data/yt_sample_sets/snapshot_033/snap_033.0.hdf5',\n",
       "  'start_index': 262144,\n",
       "  'end_index': 280105},\n",
       " {'file': '/home/chavlin/hdd/data/yt_data/yt_sample_sets/snapshot_033/snap_033.1.hdf5',\n",
       "  'start_index': 0,\n",
       "  'end_index': 262144}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datafiles[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bc6faab-6257-4a56-aa18-c603216ee0f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(datafiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f9ae819-74fd-4420-b71e-75405d1a218f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\"> </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px;\">Client</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Client-d3ebc433-e5e8-11ec-a9b9-00d8616a0a50</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "\n",
       "        <tr>\n",
       "        \n",
       "            <td style=\"text-align: left;\"><strong>Connection method:</strong> Cluster object</td>\n",
       "            <td style=\"text-align: left;\"><strong>Cluster type:</strong> distributed.LocalCluster</td>\n",
       "        \n",
       "        </tr>\n",
       "\n",
       "        \n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:8787/status\" target=\"_blank\">http://127.0.0.1:8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\"></td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        </table>\n",
       "\n",
       "        \n",
       "            <details>\n",
       "            <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Cluster Info</h3></summary>\n",
       "            <div class=\"jp-RenderedHTMLCommon jp-RenderedHTML jp-mod-trusted jp-OutputArea-output\">\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\">\n",
       "    </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px; margin-top: 0px;\">LocalCluster</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">ad160c39</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard:</strong> <a href=\"http://127.0.0.1:8787/status\" target=\"_blank\">http://127.0.0.1:8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Workers:</strong> 4\n",
       "                </td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total threads:</strong> 8\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total memory:</strong> 31.20 GiB\n",
       "                </td>\n",
       "            </tr>\n",
       "            \n",
       "            <tr>\n",
       "    <td style=\"text-align: left;\"><strong>Status:</strong> running</td>\n",
       "    <td style=\"text-align: left;\"><strong>Using processes:</strong> True</td>\n",
       "</tr>\n",
       "\n",
       "            \n",
       "        </table>\n",
       "\n",
       "        <details>\n",
       "            <summary style=\"margin-bottom: 20px;\">\n",
       "                <h3 style=\"display: inline;\">Scheduler Info</h3>\n",
       "            </summary>\n",
       "\n",
       "            <div style=\"\">\n",
       "    <div>\n",
       "        <div style=\"width: 24px; height: 24px; background-color: #FFF7E5; border: 3px solid #FF6132; border-radius: 5px; position: absolute;\"> </div>\n",
       "        <div style=\"margin-left: 48px;\">\n",
       "            <h3 style=\"margin-bottom: 0px;\">Scheduler</h3>\n",
       "            <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Scheduler-8410936a-393a-4242-b751-ed79e2c3ecf1</p>\n",
       "            <table style=\"width: 100%; text-align: left;\">\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Comm:</strong> tcp://127.0.0.1:43047\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Workers:</strong> 4\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Dashboard:</strong> <a href=\"http://127.0.0.1:8787/status\" target=\"_blank\">http://127.0.0.1:8787/status</a>\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total threads:</strong> 8\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Started:</strong> Just now\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total memory:</strong> 31.20 GiB\n",
       "                    </td>\n",
       "                </tr>\n",
       "            </table>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <details style=\"margin-left: 48px;\">\n",
       "        <summary style=\"margin-bottom: 20px;\">\n",
       "            <h3 style=\"display: inline;\">Workers</h3>\n",
       "        </summary>\n",
       "\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: 0</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tcp://127.0.0.1:40135\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 2\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:35951/status\" target=\"_blank\">http://127.0.0.1:35951/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 7.80 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tcp://127.0.0.1:36251\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /home/chavlin/src/yt_general/daskify/minimal_particle_read_testing/dask-worker-space/worker-za32dish\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: 1</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tcp://127.0.0.1:46175\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 2\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:34707/status\" target=\"_blank\">http://127.0.0.1:34707/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 7.80 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tcp://127.0.0.1:38659\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /home/chavlin/src/yt_general/daskify/minimal_particle_read_testing/dask-worker-space/worker-n98k6imw\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: 2</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tcp://127.0.0.1:33061\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 2\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:41101/status\" target=\"_blank\">http://127.0.0.1:41101/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 7.80 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tcp://127.0.0.1:46203\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /home/chavlin/src/yt_general/daskify/minimal_particle_read_testing/dask-worker-space/worker-87n6eesy\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: 3</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tcp://127.0.0.1:39667\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 2\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:36803/status\" target=\"_blank\">http://127.0.0.1:36803/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 7.80 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tcp://127.0.0.1:46741\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /home/chavlin/src/yt_general/daskify/minimal_particle_read_testing/dask-worker-space/worker-lu7jxl13\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "\n",
       "    </details>\n",
       "</div>\n",
       "\n",
       "        </details>\n",
       "    </div>\n",
       "</div>\n",
       "            </details>\n",
       "        \n",
       "\n",
       "    </div>\n",
       "</div>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:43047' processes=4 threads=8, memory=31.20 GiB>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "444ad718-92a4-407b-810c-32b460df5219",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.manual_loads import get_yt_chunks, serial_read_concat, delay_then_concat, read_delayed_array, manual_sum_by_chunk, read_chunk\n",
    "from src.manual_loads import in_mem_from_dask_futures, sum_of_futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a06fe98f-6d33-4002-a107-55b5562d7e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"snapshot_033/snap_033.0.hdf5\"\n",
    "field_type = \"PartType0\"\n",
    "field = \"Density\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1583a5b9-02b2-416d-a3a5-2b09e2c8475f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "yt : [INFO     ] 2022-06-06 17:34:35,135 Parameters: current_time              = 4.343952725460923e+17 s\n",
      "yt : [INFO     ] 2022-06-06 17:34:35,136 Parameters: domain_dimensions         = [1 1 1]\n",
      "yt : [INFO     ] 2022-06-06 17:34:35,137 Parameters: domain_left_edge          = [0. 0. 0.]\n",
      "yt : [INFO     ] 2022-06-06 17:34:35,137 Parameters: domain_right_edge         = [25. 25. 25.]\n",
      "yt : [INFO     ] 2022-06-06 17:34:35,138 Parameters: cosmological_simulation   = 1\n",
      "yt : [INFO     ] 2022-06-06 17:34:35,138 Parameters: current_redshift          = -4.811891664902035e-05\n",
      "yt : [INFO     ] 2022-06-06 17:34:35,138 Parameters: omega_lambda              = 0.762\n",
      "yt : [INFO     ] 2022-06-06 17:34:35,138 Parameters: omega_matter              = 0.238\n",
      "yt : [INFO     ] 2022-06-06 17:34:35,139 Parameters: omega_radiation           = 0.0\n",
      "yt : [INFO     ] 2022-06-06 17:34:35,139 Parameters: hubble_constant           = 0.73\n",
      "yt : [INFO     ] 2022-06-06 17:34:35,216 Allocating for 4.194e+06 particles\n",
      "Loading particle index: 100%|███████████████████████████████████| 12/12 [00:00<00:00, 490.88it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datafiles = get_yt_chunks(file)\n",
    "len(datafiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da59ea1a-908b-450d-b3e2-cf4b5f4c600a",
   "metadata": {},
   "source": [
    "### loading the full array\n",
    "\n",
    "First, we'll check the time to load all particles into an array. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd92f69-ee07-496f-985f-c0c511f77f91",
   "metadata": {},
   "source": [
    "`serial_read_concat` : loops over chunks, appends data to a list and then concatenated (pretty much what yt currently does)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66e62d76-3cc0-4592-a935-6eb653d89e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.64 ms ± 380 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "data_serial = serial_read_concat(datafiles, field_type, field)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a494cb1-b528-44b2-92fa-18adb1b81016",
   "metadata": {},
   "source": [
    "Now a couple dask approaches\n",
    "\n",
    "`delay_then_concat` : loops over chunks, use dask.delayed to read chunks into memory, concatenates after loading into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c1173fe-0dad-443a-8c3c-806fbc637746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.8 ms ± 10.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "data_from_delayed = delay_then_concat(datafiles, field_type, field)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3d9c91-4709-49e7-904e-046a2dbb37e0",
   "metadata": {},
   "source": [
    "`in_mem_from_dask_futures`: loop over chunks, immediates submits a chunk for reading and then concatenates after all future reads return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e396605f-c36a-4269-ac91-2e8f32cf712d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.5 ms ± 4.85 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "data_from_future = in_mem_from_dask_futures(c, datafiles, field_type, field)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3455e6-2d9e-4bf1-b250-985188851096",
   "metadata": {},
   "source": [
    "`read_delayed_array`: loop over chunks, create full dask array and concatenate. This returns a dask array, so need to call `compute` to get the in-memory array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c5ea5bd-1d75-4ec4-86e9-663277e18fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 ms ± 2.02 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "data_delayed = read_delayed_array(datafiles, field_type, field)\n",
    "data_from_array = data_delayed.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd2b749-cbf6-47dd-8922-084dc5aab145",
   "metadata": {},
   "source": [
    "So from this, we can see that the dask-version are a fair bit slower -- from a factor of 4.23 to 6.91 slower, depending on the method. This is consistent with the full daskified particle reader for yt, indicating that it's primarily the communication of the np arrays corresponding to each chunk. \n",
    "\n",
    "It also indicates that the daskified particle reader should be a use-dependent feature. When simply reading selections into memory, it is probably going to be faster to use yt's existing reader rather than the daskified one. But we'll explore this further with larger datasets down below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad36baa8-8fa5-401c-a670-15f981331308",
   "metadata": {},
   "source": [
    "### reductions on the array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e303c82-55a8-4ac0-bc88-4d99ba83b99d",
   "metadata": {},
   "source": [
    "Beyond reading yt chunks, we can use dask to compute reductions. Depending on the calculation, the communication requirement between dask processes should be a good deal lower since the whole data range need not be transferred, only the reduced result.\n",
    "\n",
    "For this, we'll use a simple `sum` reduction that simply adds values from each chunks. This is easily parallelized -- add the values of each chunk then sum the intermediate sums to get the cross-chunk sum. \n",
    "\n",
    "Let's start with a reference where we read the whole array and sum it.\n",
    "\n",
    "`serial_read_concat`: reads the whole arrays into memory, then sums (**requires whole array in memory**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9dbc364f-1a92-468b-b407-39df6977aaf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.24 ms ± 241 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "data_serial = serial_read_concat(datafiles, field_type, field)\n",
    "dsum = data_serial.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae0515f-5865-4b71-9f24-2b31b0a81f3e",
   "metadata": {},
   "source": [
    "And another reference that manually sums each chunk as it is read. \n",
    "\n",
    "`manual_sum_by_chunk`: manual loop over chunks, summing each chunk and adding to total (`val += chunk_data.sum()`), requires one chunk in memory at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c7573a2-4fb7-4730-ac28-ae784a6775ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.15 ms ± 222 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "msum = manual_sum_by_chunk(datafiles, field_type, field)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc0ad2d-cf72-491b-94d9-1d1578529c00",
   "metadata": {},
   "source": [
    "`read_delayed_array` constructs a delayed array from chunks, sums on the dask array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29b99249-cc12-4728-832a-024029e7105a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.7 ms ± 25.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "x = read_delayed_array(datafiles, field_type, field)\n",
    "sum_from_delayed = x.sum().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796e1bf3-df99-4b94-8088-7f563162cfce",
   "metadata": {},
   "source": [
    "`sum_of_futures` : uses client.submit to get the sum of each chunk as a future then adds those results as the come back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bccdf1d6-274f-4537-a205-66ad355fe566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.9 ms ± 3.8 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "future_sum = sum_of_futures(c, datafiles, field_type, field)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62642dd-efa3-445f-8488-78b90af32392",
   "metadata": {},
   "source": [
    "So even in this case, the plain serial sum is faster. It's interesting that using dask's `client.submit()` functionality to construct a list of futures containing the sums by chunk is faster than constructing a full dask array -- this is likely due to the overhead of constructing the full dask graph associated with a dask array. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3563b01e-8171-48bd-b238-178e57529c9e",
   "metadata": {},
   "source": [
    "## A larger dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e290f5ec-9ee8-41aa-93e1-4239f1efd2b4",
   "metadata": {},
   "source": [
    "The case above contains just under ~2 million `(\"PartType0\", \"Density\")` particles across 12 hdf files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1cc51f47-73ea-40c2-8da0-6531ab6e28e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.941226, 12)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_serial = serial_read_concat(datafiles, field_type, field)\n",
    "(data_serial.shape[0]/1e6, len(datafiles))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8d4913-d244-4bfe-ac08-e3270a334c88",
   "metadata": {},
   "source": [
    "and it's possible that the relative performance for the daskified cases will improve with larger datasets. So let's try out another:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f876307a-275d-49ec-903b-7a21d170507c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "yt : [INFO     ] 2022-06-06 17:35:07,646 Parameters: current_time              = 4.361428036047735e+17 s\n",
      "yt : [INFO     ] 2022-06-06 17:35:07,647 Parameters: domain_dimensions         = [1 1 1]\n",
      "yt : [INFO     ] 2022-06-06 17:35:07,647 Parameters: domain_left_edge          = [0. 0. 0.]\n",
      "yt : [INFO     ] 2022-06-06 17:35:07,648 Parameters: domain_right_edge         = [8.47125 8.47125 8.47125]\n",
      "yt : [INFO     ] 2022-06-06 17:35:07,648 Parameters: cosmological_simulation   = 1\n",
      "yt : [INFO     ] 2022-06-06 17:35:07,649 Parameters: current_redshift          = 2.220446049250313e-16\n",
      "yt : [INFO     ] 2022-06-06 17:35:07,649 Parameters: omega_lambda              = 0.693\n",
      "yt : [INFO     ] 2022-06-06 17:35:07,649 Parameters: omega_matter              = 0.307\n",
      "yt : [INFO     ] 2022-06-06 17:35:07,650 Parameters: omega_radiation           = 0.0\n",
      "yt : [INFO     ] 2022-06-06 17:35:07,650 Parameters: hubble_constant           = 0.6777\n",
      "yt : [INFO     ] 2022-06-06 17:35:07,909 Allocating for 1.329e+07 particles\n",
      "Loading particle index: 100%|███████████████████████████████████| 32/32 [00:00<00:00, 677.51it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6.381559, 32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = \"snapshot_028_z000p000/snap_028_z000p000.0.hdf5\"\n",
    "datafiles = get_yt_chunks(file)\n",
    "data_serial = serial_read_concat(datafiles, field_type, field)\n",
    "(data_serial.shape[0]/1e6, len(datafiles))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46c3415-e66f-478c-8797-17c9fec34c9e",
   "metadata": {},
   "source": [
    "### loading the full array\n",
    "\n",
    "Repeating the same load methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "707fe9f8-be27-456b-a915-fde9a302af79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73.6 ms ± 1.82 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "data_serial = serial_read_concat(datafiles, field_type, field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b20ca290-2cb0-4e58-9bd8-b6fe76deb626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87.2 ms ± 10.4 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "data_from_delayed = delay_then_concat(datafiles, field_type, field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e711472-c1d1-4162-a29b-2a159c200fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87.5 ms ± 3.57 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "data_from_future = in_mem_from_dask_futures(c, datafiles, field_type, field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b690b3e-c77e-4b90-8756-cce1ea3bff1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102 ms ± 4.07 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "data_delayed = read_delayed_array(datafiles, field_type, field)\n",
    "data_from_array = data_delayed.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9375751-ce78-468e-8964-73368d8addd2",
   "metadata": {},
   "source": [
    "so we see that with the larger number of particles and chunk-files, the performance is **much** more comparable when loading the full array. Dask is still a little slower, but now within a factor of 1.1-1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59093a3-aa8d-46e8-8951-d398230df082",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "058f7a3c-de3f-493d-a315-5fd35c832b00",
   "metadata": {},
   "source": [
    "### reductions\n",
    "\n",
    "And repeating the reduction methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dd1e7ef4-b601-4a22-9503-09b8b4c4a425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79.4 ms ± 1.62 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "data_serial = serial_read_concat(datafiles, field_type, field)\n",
    "dsum = data_serial.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9801aa3a-8151-40ea-be20-c7da5c2c352b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.9 ms ± 2.2 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "msum = manual_sum_by_chunk(datafiles, field_type, field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb89aa11-794f-44ee-92db-5956f7924152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87.6 ms ± 7.8 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "x = read_delayed_array(datafiles, field_type, field)\n",
    "sum_from_delayed = x.sum().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "16510f08-6a77-433b-93c6-1da5243c2963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79.5 ms ± 2.65 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "future_sum = sum_of_futures(c, datafiles, field_type, field)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f74719a-5157-4cf0-b2ab-1edc40c8e0f2",
   "metadata": {},
   "source": [
    "and again, we have much more comparable results. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a13230-f9ed-4287-9ec4-3c801ac82747",
   "metadata": {},
   "source": [
    "### simulating an even larger dataset\n",
    "\n",
    "Since we've detached ourselves from the yt api, it's easy to simulate **much** larger datasets by re-reading `datafiles`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d506d46c-3ece-4787-856c-2a22ca279bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "320"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_multiplier = 10\n",
    "more_files = datafiles * file_multiplier\n",
    "len(more_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97b2220-6a8c-4cc0-94fe-882f621bddbb",
   "metadata": {},
   "source": [
    "the effective size in millions of particles if we read all the data in would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "842b026c-5d24-437e-a378-8c82c2dc148e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.81559\n"
     ]
    }
   ],
   "source": [
    "data_serial = serial_read_concat(datafiles, field_type, field)\n",
    "print(data_serial.size * file_multiplier / 1e6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d8ed2f-9066-4018-bd17-692ba79ae0f7",
   "metadata": {},
   "source": [
    "### loading the full array \n",
    "\n",
    "~64 million particles should be fine in memory, so let's read it all in again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "294f4d03-3f8e-46f3-bcd4-ec84d557d934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "801 ms ± 12.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "_ = serial_read_concat(more_files, field_type, field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c6eb1b72-7684-470f-a0f2-0b42dbb0055b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "689 ms ± 35.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "_ = delay_then_concat(more_files, field_type, field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6ac25ba1-ccef-496b-b1b0-af8de0fa131e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117 ms ± 8.78 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "_ = in_mem_from_dask_futures(c, more_files, field_type, field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9217450a-d7d1-4b44-b845-3e1efaff5b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "826 ms ± 55.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "data_delayed = read_delayed_array(more_files, field_type, field)\n",
    "_ = data_delayed.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdccdbe5-3169-4fa1-8bce-64b8cd7e3038",
   "metadata": {},
   "source": [
    "Now we're starting to see some improvements from the dask reads! At least in the cases where we don't build a full dask array. The dask futures are surprisingly significantly faster. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1044b4-cce1-4c36-bc98-d69d0e42fdb7",
   "metadata": {},
   "source": [
    "### reductions\n",
    "\n",
    "and now the reductions again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "385b82cf-f48e-496d-a32e-9815de2809c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "830 ms ± 23.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "data_serial = serial_read_concat(more_files, field_type, field)\n",
    "dsum = data_serial.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3a322ce6-f29f-4305-8ba3-11cd559790ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "713 ms ± 15.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "msum = manual_sum_by_chunk(more_files, field_type, field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "78c1a261-0f08-4af6-be42-37b890b3b437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "554 ms ± 37.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "x = read_delayed_array(more_files, field_type, field)\n",
    "sum_from_delayed = x.sum().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "555b1472-4d59-4439-b0ca-105911802cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "496 ms ± 46.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "future_sum = sum_of_futures(c, more_files, field_type, field)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c76d551-ed23-4275-a82a-af16d4f38a74",
   "metadata": {},
   "source": [
    "similar to loading the full array, we see dask is a bit faster, with the best performance from dask's futures\n",
    "\n",
    "## a too-large for memory example\n",
    "\n",
    "What happens when we go **even larger**??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7cd3f460-fc06-446f-a6dd-9819125a2a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_multiplier = 2000\n",
    "more_files = datafiles * file_multiplier\n",
    "len(more_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "19c8d817-2286-4e76-8654-39a5171b3b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.763118\n"
     ]
    }
   ],
   "source": [
    "data_serial = serial_read_concat(datafiles, field_type, field)\n",
    "print(data_serial.size * file_multiplier / 1e9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702b9b9c-bc58-4b1b-853d-8041f05547e1",
   "metadata": {},
   "source": [
    "12.7 billion elements can't load on my machine, so we'll just test the reductions that do not require the full array. It also takes a fair bit of time, so we'll just run a single iteration.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9ef63f5f-432a-40d6-b416-f90fb09dab06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 22s, sys: 6.71 s, total: 2min 29s\n",
      "Wall time: 2min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "msum = manual_sum_by_chunk(more_files, field_type, field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c9461927-b24c-4da1-b375-7e580d95f5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 47s, sys: 2.7 s, total: 2min 49s\n",
      "Wall time: 3min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x = read_delayed_array(more_files, field_type, field)\n",
    "sum_from_delayed = x.sum().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c979197c-25ea-49de-96ac-5bb1a4f156af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 7s, sys: 6.19 s, total: 1min 13s\n",
      "Wall time: 1min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "future_sum = sum_of_futures(c, more_files, field_type, field)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f2a292-014b-4e61-9dc5-3ff95abb4611",
   "metadata": {},
   "source": [
    "And we see even more speedup from dask in the futures case. The delayed array is actually slower, but based on having run that cell a few times, it's got a lot variance in time -- I saw as fast as 2 mins. So definitely worth it for huge amounts of data...\n",
    "\n",
    "\n",
    "### caveats\n",
    "\n",
    "Some notes on things that could use further investigation:\n",
    "\n",
    "I've only tested one client setup here (4 workers, 2 threads per worker), it's possible other configurations could improve dask performance.\n",
    "\n",
    "More complex reduction operations could also enhance the relative performance of dask. \n",
    "\n",
    "## Summary\n",
    "\n",
    "Some takeways:\n",
    "\n",
    "Serializing the yt objections (datasets, indexes) does not add much overhead -- here we've extracted chunk info from the yt objects and still see similar read times to the full daskified readers. So the overhead comes from chunked-data communication and dask internals.\n",
    "\n",
    "For larger amounts of data, the dask reads and reductions are either on par or faster than the single process serial chunking. Using dask's `client.submit()` functionality tends to be faster than building full dask arrays. So in internal-only yt methods, it may be worth simply using dask's futures implementation -- this, however, necessitates some explicit client handling that would be a bit more complex to code.\n",
    "\n",
    "Using full dask arrays will mostly be useful as a user-feature and for interoperability with other packages -- the extra overhead is probably not worth it in yt's internal read methods. But the ease with which a user could write their own parallel calculations without knowing yt's internal chunking mechanics is potentially very useful. \n",
    "\n",
    "**So the main takeaway** is that the load or reduction method should be situation dependent. For many users, if simply loading a yt selection, it's likely that using yt's existing chunk-iteration methods is totally sufficient. But for larger datasets with more chunks, using a daskified reader is comparable or better than yt's existing reader. This suggests that having some combination of keyword arguments and configuration options is the way to go -- allowing a user to turn on the dask reads and return dask arrays only when they want/need it. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e554e937-013d-43e6-a5ed-e02ebea393a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
